{"cells":[{"source":"# **Your first neural net**\nAll that buzz around AI and Deep Learning, but we already promised you it is not so scary when you take a look under the hood.\n\nYou're going to create your first neural network, to solve a classification task.\n\nYou are working with labelled sensor data which has:\n\n- 16 input columns, representing 16 features coming from a movement sensor of a smartwatch.\n- a target column representing one of 4 movement types: walking, running, sitting, lying.\nAll the ingredients have been loaded for you: the Sequential() model and the Dense() layer -- you just have to put the ingredients in the right order, just like stacking pancakes!\n\n- Initialize a Sequential() network.\n- Set a fully connected Dense() hidden layer with 8 units (neurons), making sure to specify the correct input size to match the dimensions of the input data.\n- Set another fully connected Dense() layer at the output, making sure to specify the correct number of output units, defined by the number of output classes of your problem.\n- Compile the model!","metadata":{},"cell_type":"markdown","id":"0251a085-cb5e-441d-ab45-2da69ddc6a69"},{"source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Initialize the model\nmodel = Sequential()\n\n# Add the hidden and the output layer, specify the layer type, number of units and input/output dimensions\nmodel.add(Dense(units=8, input_dim=16, activation='relu'))\nmodel.add(Dense(units=4, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"executionCancelledAt":null,"executionTime":30,"lastExecutedAt":1690982703916,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Initialize the model\nmodel = Sequential()\n\n# Add the hidden and the output layer, specify the layer type, number of units and input/output dimensions\nmodel.add(Dense(units=8, input_dim=16, activation='relu'))\nmodel.add(Dense(units=4, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","outputsMetadata":{"0":{"height":134,"type":"stream"}}},"cell_type":"code","id":"255abb4e-2805-427e-a47b-a72ae66ad685","execution_count":15,"outputs":[]},{"source":"# **Rolling in the deep**\nYou have been asked by the local police department to produce a Deep Learning model for license plate reading.\n\nYour input data are images of digits, 28 pixels wide and 28 pixels tall, each with a label stating which of the 10 possible digits is present on the picture.\n\nThe Sequential() model is already loaded, which you will use to build a Deep Neural Network using the following layers:\n \n- Conv2D() - 2D convolutional layer\n- MaxPooling2D() - pooling layer\n- Flatten() - flattening layer\n- Dense() - fully connected layer","metadata":{},"cell_type":"markdown","id":"0386c5bd-365f-4284-adcc-2b017656ddd4"},{"source":"- Initialize the model and set a 2D convolutional layer with 64 filters of size 3x3 at the input.\n- Add a MaxPooling2D() layer, with default parameters, followed by a flattening layer, to reshape the signal from a 2-dimensional to a 1-dimensional format.\n- Add a fully connected Dense() layer with a softmax activation function and 10 neurons for 10 target classes present in our training set.\n- Compile the model.","metadata":{},"cell_type":"markdown","id":"e52cfbd0-5ef4-4777-b29a-347416308ce3"},{"source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\n# Initialize the model\nmodel = Sequential()\n\n# Create your 5-layer network (input specified implicitly with 1st layer)\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D(pool_size=(1, 1), strides=(1, 1)))\nmodel.add(Flatten())\nmodel.add(Dense(units=10, activation='softmax'))\n\n# Set fitting hyper-parameters and compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"executionCancelledAt":null,"executionTime":35,"lastExecutedAt":1690982692284,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\n# Initialize the model\nmodel = Sequential()\n\n# Create your 5-layer network (input specified implicitly with 1st layer)\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D(pool_size=(1, 1), strides=(1, 1)))\nmodel.add(Flatten())\nmodel.add(Dense(units=10, activation='softmax'))\n\n# Set fitting hyper-parameters and compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","outputsMetadata":{"0":{"height":349,"type":"stream"}}},"cell_type":"code","id":"37a5e598-69cc-4162-9f3f-1533518fee63","execution_count":13,"outputs":[]},{"source":"# **One-liner modeling**\nModern Deep Learning libraries already help you by abstracting an ever bigger part of work that was once required to build neural networks.\n\nAs you could already see, in just 10 lines of code you can specify an extremely powerful network that could be trained for days, using terabytes of data.\n\nBut sometimes you want to go even further into abstraction: when you have a typical network specification that you often use, changing only a handful of parameters, it's a good idea to enclose it in a function.\n\nThat's what you will do in this exercise, and later reuse the created function for further exercises.","metadata":{},"cell_type":"markdown","id":"60ae9924-0626-4263-a2f5-4cd31c9dfc2b"},{"source":"def make_deep_net(input_shape, n_output_classes, n_kernels=32, kernel_size=(3, 3)):\n    # Initialize the sequential model\n    model = Sequential()\t\n    # Add the convolutional layer (containing implicitly the input layer)\n    model.add(Conv2D(input_shape=input_shape, filters=n_kernels, kernel_size=kernel_size, activation='relu'))\n    # Add the flattening layer\n    model.add(Flatten())\t\n    # Add the fully connected layer\n    model.add(Dense(n_output_classes, activation='softmax')) \n    # Compile the model\n    model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n    \n    return model","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1690982744830,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def make_deep_net(input_shape, n_output_classes, n_kernels=32, kernel_size=(3, 3)):\n    # Initialize the sequential model\n    model = Sequential()\t\n    # Add the convolutional layer (containing implicitly the input layer)\n    model.add(Conv2D(input_shape=input_shape, filters=n_kernels, kernel_size=kernel_size, activation='relu'))\n    # Add the flattening layer\n    model.add(Flatten())\t\n    # Add the fully connected layer\n    model.add(Dense(n_output_classes, activation='softmax')) \n    # Compile the model\n    model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n    \n    return model"},"cell_type":"code","id":"35fb2e6f-134c-46bd-a04f-876c02828077","execution_count":16,"outputs":[]},{"source":"# **One-line evaluation**\nAlthough constant progress is being made, not all outputs of your modeling and evaluation algorithms come in a human readable shape.\n\nVery often they come in plain arrays of unnamed values, requiring you to read through the documentation in order to interpret what each value means.\n\nIn such cases it is again clever to make wrapper functions that format and return the results in a neat and understandable way.\n\nThe evaluation result, stored in the variable score, is an array whose first element is the loss and the second accuracy of the model over the given dataset.\n\n- Place the input variables x_test and y_test into the appropriate arguments of the model's .evaluate() method.\n- Use the first element of the score array to print out the loss and the second element to print out the resulting accuracy.","metadata":{},"cell_type":"markdown","id":"6d58d57b-6216-4a10-9b82-1d00973b34cf"},{"source":"def evaluate_deep_net(model, x_test, y_test):\n    # Generate the test predictions and evaluate against the ground truth\n    score = model.evaluate(x=x_test, y=y_test)\n    # Print the evaluation results in a human readable form\n    print('Test loss: %.2f' % score[0])\n    print('Test accuracy: %.2f %%' % (100*score[1]))","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1690982674702,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def evaluate_deep_net(model, x_test, y_test):\n    # Generate the test predictions and evaluate against the ground truth\n    score = model.evaluate(x=x_test, y=y_test)\n    # Print the evaluation results in a human readable form\n    print('Test loss: %.2f' % score[0])\n    print('Test accuracy: %.2f %%' % (100*score[1]))"},"cell_type":"code","id":"df4fe333-4f0d-41e8-879d-ec3a68bd82fa","execution_count":11,"outputs":[]},{"source":"# **Deep Learning for Digit Recognition**\nDeep Learning models excel at classifying unstructured data, such as images and text. Common problems solved by Deep Learning include image classification, object detection, text translation, and text summarization.\n\nIn this exercise, you will use the functions defined in previous exercises (make_deep_net() and evaluate_deep_net()) to build a Deep Neural Network for recognizing hand-written digits.\n\nYou will train and test your model using the well known MNIST dataset, which contains a collection of images of individual hand-written digits, each 28x28 pixels big.\n\nThe dataset is pre-loaded and split into the training and test sets:(x_train, y_train) and (x_test, y_test).","metadata":{},"cell_type":"markdown","id":"9ee47b6a-92ae-443b-b107-a2b2dc3f49fd"},{"source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n\n# Reshape the input data\nX_train = X_train.reshape((X_train.shape[0], 28*28))\nX_test = X_test.reshape((X_test.shape[0], 28*28))\n\n# Construct the Deep Neural Network\ndeep_net = Sequential()\ndeep_net.add(Dense(64, activation='relu', input_shape=(28*28,)))\ndeep_net.add(Dense(10, activation='softmax'))\n\n# Compile the Deep Neural Network\ndeep_net.compile(optimizer='adam',\n                 loss='sparse_categorical_crossentropy',\n                 metrics=['accuracy'])\n\n# Train the Deep Neural Network\ndeep_net.fit(X_train, y_train,\n             validation_data=(X_test, y_test),\n             batch_size=128,\n             epochs=3)\n\n# Estimate the network performance\ndeep_net.evaluate(X_test, y_test)","metadata":{"executionCancelledAt":null,"executionTime":4150,"lastExecutedAt":1690982664940,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n\n# Reshape the input data\nX_train = X_train.reshape((X_train.shape[0], 28*28))\nX_test = X_test.reshape((X_test.shape[0], 28*28))\n\n# Construct the Deep Neural Network\ndeep_net = Sequential()\ndeep_net.add(Dense(64, activation='relu', input_shape=(28*28,)))\ndeep_net.add(Dense(10, activation='softmax'))\n\n# Compile the Deep Neural Network\ndeep_net.compile(optimizer='adam',\n                 loss='sparse_categorical_crossentropy',\n                 metrics=['accuracy'])\n\n# Train the Deep Neural Network\ndeep_net.fit(X_train, y_train,\n             validation_data=(X_test, y_test),\n             batch_size=128,\n             epochs=3)\n\n# Estimate the network performance\ndeep_net.evaluate(X_test, y_test)","outputsMetadata":{"0":{"height":212,"type":"stream"}}},"cell_type":"code","id":"a40cf7c5-69e1-44f3-82fb-e1d1a93e1d2a","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/3\n469/469 [==============================] - 1s 3ms/step - loss: 4.1606 - accuracy: 0.7697 - val_loss: 0.7752 - val_accuracy: 0.8379\nEpoch 2/3\n469/469 [==============================] - 1s 2ms/step - loss: 0.6188 - accuracy: 0.8555 - val_loss: 0.5633 - val_accuracy: 0.8827\nEpoch 3/3\n469/469 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8906 - val_loss: 0.4248 - val_accuracy: 0.9020\n313/313 [==============================] - 0s 859us/step - loss: 0.4248 - accuracy: 0.9020\n"},{"output_type":"execute_result","data":{"text/plain":"[0.4248087406158447, 0.9020000100135803]"},"metadata":{},"execution_count":10}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}